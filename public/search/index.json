[{"content":"For this analysis I decided to use the CDC NHANES data (2017 - pre pandemic 2020). I found this guide on importing and cleaning NHANES data using the nhanesA package, and found it very useful in this project.\nNHANES is a very large survey conducted by the CDC that is a crucial resource for public health data analysis, and is all available for free public use. As this was my first time using this dataset, I decided to keep it simple, but I will definitely be coming back to it as there is just so much information collected that can be used for all types of public health analysis.\nLoad Packages 1 2 3 4 5 6 7 suppressPackageStartupMessages({ library(tidyverse) library(nhanesA) library(tableone) library(arsenal) library(agricolae) }) Grab Datasets that I Need Here I used the nhanesA package to get the datasets (or Data Files as they are called on the NHANES site), the two that I needed for this analysis were the demographics dataset\n1 2 demo \u0026lt;- nhanes(\u0026#34;P_DEMO\u0026#34;) demo_translate \u0026lt;- nhanesTranslate(\u0026#34;P_DEMO\u0026#34;, names(demo), data = demo) 1 ## Translated columns: RIDSTATR RIAGENDR RIDRETH1 RIDRETH3 RIDEXMON DMDBORN4 DMDYRUSZ DMDEDUC2 DMDMARTZ RIDEXPRG SIALANG SIAPROXY SIAINTRP FIALANG FIAPROXY FIAINTRP MIALANG MIAPROXY MIAINTRP AIALANGA and the total cholesterol one\n1 2 exam \u0026lt;- nhanes(\u0026#34;P_TCHOL\u0026#34;) exam_translate \u0026lt;- nhanesTranslate(\u0026#34;P_TCHOL\u0026#34;, names(exam), data = exam) 1 2 ## Warning in nhanesTranslate(\u0026#34;P_TCHOL\u0026#34;, names(exam), data = exam): No columns ## were translated Retain Useful Variables Here I am only retaining the variables that I want to bring into my final dataset.\nFrom the demographics file, I decided on SEQN which is the sequence number that will help us merge the two datasets, RIDEXPRG which indicates if the respondent is pregnant, RIAGENDR which stores the participants gender, RIDAGEYR which stores the participant\u0026rsquo;s age in years, and lastly RIDRETH3 which categorizes the participant\u0026rsquo;s race.\nFrom the exam file I only extracted the sequence number, and lab value for total cholesterol.\n1 2 3 4 5 demo_select \u0026lt;- demo_translate %\u0026gt;% select(SEQN, RIDEXPRG, RIAGENDR, RIDAGEYR, RIDRETH3) exam_select \u0026lt;- exam_translate %\u0026gt;% select(SEQN, LBXTC) Merge the Data Using SEQN to Match Values The structure of the NHANES database makes it easy to match which lab values belong to which patient in including the SEQN column on the seperate datasets. I also went ahead and dropped the SEQN column when I was done merging as I only needed it for that task.\n1 2 3 merged_data \u0026lt;- merge(demo_select, exam_select, by = c(\u0026#34;SEQN\u0026#34;), all = TRUE) merged_data$SEQN \u0026lt;- NULL Initial Investigaton of the Data Here I want to see the different categories and how much we have of each so that I can apply the eligibility criteria and recode the values properly.\n1 2 3 4 initial_table \u0026lt;- CreateTableOne(data = merged_data, includeNA = TRUE) print(initial_table, showAllLevels = TRUE) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 ## ## level ## n ## RIDEXPRG (%) Yes, positive lab pregnancy test or self-reported pregnant at exam ## The participant was not pregnant at exam ## Cannot ascertain if the participant is pregnant at exam ## \u0026lt;NA\u0026gt; ## RIAGENDR (%) Male ## Female ## RIDAGEYR (mean (SD)) ## RIDRETH3 (%) Mexican American ## Other Hispanic ## Non-Hispanic White ## Non-Hispanic Black ## Non-Hispanic Asian ## Other Race - Including Multi-Racial ## LBXTC (mean (SD)) ## ## Overall ## n 15560 ## RIDEXPRG (%) 87 ( 0.6) ## 1604 (10.3) ## 183 ( 1.2) ## 13686 (88.0) ## RIAGENDR (%) 7721 (49.6) ## 7839 (50.4) ## RIDAGEYR (mean (SD)) 33.74 (25.32) ## RIDRETH3 (%) 1990 (12.8) ## 1544 ( 9.9) ## 5271 (33.9) ## 4098 (26.3) ## 1638 (10.5) ## 1019 ( 6.5) ## LBXTC (mean (SD)) 177.46 (40.36) Apply Eligibility Criteria I decided for the eligibility criteria to exclude pregnant women, as well as those under the age of 20, I did that using dplyr\u0026rsquo;s filter() function, I also filtered out the columns where there was no total cholesterol lab value as that is not useful to my analysis.\n1 2 3 4 analytic_data \u0026lt;- merged_data %\u0026gt;% filter(!is.na(LBXTC), RIDAGEYR \u0026gt;= 20, RIDEXPRG != \u0026#34;Yes, positive lab pregnancy test or self-reported pregnant at exam\u0026#34; | is.na(RIDEXPRG)) Recode and Make Categories In this section, I created several new variables using dplyr\u0026rsquo;s mutate() function. I created the age_cat variable that groups the participants by age, the total_cholesterol_cat variable that groups the lab values by their normal, borderline and high ranges, and I also simplified the race data into more concise and broad categories.\nI also renamed the remaining variables to match the naming conventions in the other newly created variables, also to give some more sense to them as NHANES is great but the variables all look like keyboard smashes to me. Their variable search tool helps with that.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 category_data \u0026lt;- analytic_data %\u0026gt;% mutate( age_cat = cut(analytic_data$RIDAGEYR, c(20, 40, 60, Inf), right = FALSE), total_cholesterol_cat = cut(analytic_data$LBXTC, c(0, 200, 240, Inf), labels = c(\u0026#34;Normal\u0026#34;, \u0026#34;Borderline\u0026#34;, \u0026#34;High\u0026#34;), right = FALSE), race = car::recode(analytic_data$RIDRETH3, \u0026#34;c(\u0026#39;Mexican American\u0026#39;, \u0026#39;Other Hispanic\u0026#39;) = \u0026#39;Hispanic\u0026#39;; \u0026#39;Non-Hispanic White\u0026#39; = \u0026#39;White\u0026#39;; \u0026#39;Non-Hispanic Black\u0026#39; = \u0026#39;Black\u0026#39;; \u0026#39;Non-Hispanic Asian\u0026#39; = \u0026#39;Asian\u0026#39;; \u0026#39;Other Race - Including Multi-Racial\u0026#39; = \u0026#39;Other\u0026#39;; else = NA\u0026#34;) ) %\u0026gt;% rename( pregnancy_status = RIDEXPRG, gender = RIAGENDR, age = RIDAGEYR, total_cholesterol = LBXTC ) %\u0026gt;% select(-RIDRETH3, -pregnancy_status) 1 2 cholesterol \u0026lt;- as_tibble(category_data) cholesterol 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## # A tibble: 7,845 × 6 ## gender age total_cholesterol age_cat total_cholesterol_cat race ## \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; ## 1 Female 29 195 [20,40) Normal Asian ## 2 Male 49 147 [40,60) Normal White ## 3 Male 36 164 [20,40) Normal White ## 4 Male 68 105 [60,Inf) Normal Other ## 5 Male 76 233 [60,Inf) Borderline White ## 6 Female 44 212 [40,60) Borderline Hispanic ## 7 Female 68 165 [60,Inf) Normal Black ## 8 Female 42 229 [40,60) Borderline Asian ## 9 Male 58 172 [40,60) Normal Hispanic ## 10 Male 44 189 [40,60) Normal White ## # ℹ 7,835 more rows Table of Total Cholesterol Categories Here I used the arsenal package to make a table displaying how the different total cholesterol categories look within our study sample.\n1 2 3 labels \u0026lt;- list(age_cat = \u0026#34;Age Range\u0026#34;, gender = \u0026#34;Gender\u0026#34;, race = \u0026#34;Race\u0026#34;) tab \u0026lt;- arsenal::tableby(total_cholesterol_cat ~ age_cat + gender + race, data = cholesterol, test = FALSE) summary(tab, labelTranslations = labels, text=TRUE) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ## ## ## | | Normal (N=5236) | Borderline (N=1873) | High (N=736) | Total (N=7845) | ## |:-----------|:---------------:|:-------------------:|:------------:|:--------------:| ## |Age Range | | | | | ## |- [20,40) | 1789 (34.2%) | 412 (22.0%) | 117 (15.9%) | 2318 (29.5%) | ## |- [40,60) | 1499 (28.6%) | 789 (42.1%) | 338 (45.9%) | 2626 (33.5%) | ## |- [60,Inf) | 1948 (37.2%) | 672 (35.9%) | 281 (38.2%) | 2901 (37.0%) | ## |Gender | | | | | ## |- Male | 2659 (50.8%) | 850 (45.4%) | 323 (43.9%) | 3832 (48.8%) | ## |- Female | 2577 (49.2%) | 1023 (54.6%) | 413 (56.1%) | 4013 (51.2%) | ## |Race | | | | | ## |- Asian | 559 (10.7%) | 271 (14.5%) | 108 (14.7%) | 938 (12.0%) | ## |- Black | 1430 (27.3%) | 400 (21.4%) | 162 (22.0%) | 1992 (25.4%) | ## |- Hispanic | 1169 (22.3%) | 432 (23.1%) | 164 (22.3%) | 1765 (22.5%) | ## |- Other | 245 (4.7%) | 96 (5.1%) | 36 (4.9%) | 377 (4.8%) | ## |- White | 1833 (35.0%) | 674 (36.0%) | 266 (36.1%) | 2773 (35.3%) | Checking Assumptions Assumption of Normal Distribution Next before I look and see if there are any statistically significant differences between the groups of my choice, I have to look and see the distribution of our data to see what kind of assumptions we can make when running the stats.\n1 2 3 4 5 6 7 ggplot(cholesterol, aes(x = total_cholesterol)) + geom_histogram(binwidth = 15, color = \u0026#34;black\u0026#34;, fill = \u0026#34;#bbbbff\u0026#34;) + labs(x = \u0026#34;Total Cholesterol (mg/dL)\u0026#34;, y = \u0026#34;Count\u0026#34;, title = \u0026#34;Total Cholesterol (mg/dL) Distribution\u0026#34;, caption = \u0026#34;Source: CDC NHANES 2017 - Pre Pandemic 2020\u0026#34;) + theme(plot.title = element_text(hjust = 0.5)) This follows a generally normal distribution, but I\u0026rsquo;m going to take a closer look as I do see outliers towards the end of our bell curve.\n1 2 cholesterol_model \u0026lt;- lm(total_cholesterol ~ race, data = cholesterol) plot(cholesterol_model, which = 2) It seems like there is a systematic deviation from the expected relationship if the data were to be normally distributed. The data is not normally distributed. Assumption of Constant Variance 1 plot(cholesterol_model, which = 3) There is constant variance throughout the data, however since our assumption of normal distribution was violated I am going to check one more assumption that would be needed to run a non parametric test assessing the differences between the central tendency of our chosen groups. Assumption of Similar Skewness for Each Category 1 2 3 4 5 6 7 8 9 ggplot(cholesterol, aes(x = total_cholesterol, fill = race)) + geom_histogram(binwidth = 15, color = \u0026#34;black\u0026#34;) + labs(x = \u0026#34;Total Cholesterol (mg/dL)\u0026#34;, y = \u0026#34;Count\u0026#34;, title = \u0026#34;Total Cholesterol (mg/dL) Distribution by Race/Hispanic Origin\u0026#34;, caption = \u0026#34;Source: CDC NHANES 2017 - Pre Pandemic 2020\u0026#34;) + theme(plot.title = element_text(hjust = 0.5)) + facet_wrap(~race) + scale_fill_manual(values = c(\u0026#34;#E6FFFD\u0026#34;, \u0026#34;#AEE2FF\u0026#34;, \u0026#34;#ACBCFF\u0026#34;, \u0026#34;#B799FF\u0026#34;, \u0026#34;#AA77FF\u0026#34;)) Looks like each category of Race/Hispanic origin does have a similar skewness. Statistical Testing Visualize Data with a Boxplot 1 2 3 4 5 6 7 8 9 10 11 ggplot(cholesterol, aes(x = race, y = total_cholesterol, fill = race)) + geom_boxplot() + scale_fill_manual(values = c(\u0026#34;#E6FFFD\u0026#34;, \u0026#34;#AEE2FF\u0026#34;, \u0026#34;#ACBCFF\u0026#34;, \u0026#34;#B799FF\u0026#34;, \u0026#34;#AA77FF\u0026#34;)) + labs( x = \u0026#34;Race/Hispanic Origin\u0026#34;, y = \u0026#34;Total Cholesterol (mg/dL)\u0026#34;, title = \u0026#34;Total Cholesterol (mg/dL) by Race/Hispanic Origin of Participant\u0026#34;, caption = \u0026#34;Source: CDC NHANES 2017 - Pre Pandemic 2020\u0026#34; ) + theme(legend.position = \u0026#34;none\u0026#34;, plot.title = element_text(hjust = 0.5)) Kruskal Wallis Test Since I checked various assumptions, and the assumption of normality was violated, I decided to go with a non parametric Kruskal Wallis Test to test my hypothesis that there is a different mean total cholesterol value between the 5 different racial/hispanic origin categories.\n1 2 options(scipen = 999) kruskal.test(total_cholesterol ~ race, data = cholesterol) 1 2 3 4 5 6 ## ## Kruskal-Wallis rank sum test ## ## data: total_cholesterol by race ## Kruskal-Wallis chi-squared = 60.582, df = 4, p-value = ## 0.000000000002188 The p value is very very small, meaning there is one or more categories that have a mean total cholesterol that differs from the other. To check which groups are causing there to be a statisticially signifigant difference, I\u0026rsquo;ll run a pairwise comparison.\nPairwise Comparison Test 1 2 pairwise.wilcox.test(cholesterol$total_cholesterol, cholesterol$race, p.adjust.method = \u0026#34;BH\u0026#34;) 1 2 3 4 5 6 7 8 9 10 11 12 ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: cholesterol$total_cholesterol and cholesterol$race ## ## Asian Black Hispanic Other ## Black 0.0000000000011 - - - ## Hispanic 0.00096 0.0000031636325 - - ## Other 0.01722 0.01722 0.77812 - ## White 0.0000031636325 0.00069 0.12485 0.61744 ## ## P value adjustment method: BH Looks like there are multiple groups in which a statistically significant difference can be observed, in fact it is present in all except Other and Hispanic, White and Hispanic, and Other and White.\nConclusion I was always hesitant to use the CDC\u0026rsquo;s NHANES dataset as it is so big and there are so many different variables but I\u0026rsquo;m glad that I found the nhanesA package as that made it so easy to do this analysis, and I\u0026rsquo;ll definitely be using it again to avoid having to dig for datasets and also having to download gigantic ones to my poor old computer lol.\nI also learned some other things during this analysis, in terms of R skills I learned about the arsenal package that builds tables to display the various categories that were pre-existing in the data, as well as the categories that I created using the cut() function based on the typical ranges used in medicine for total cholesterol.\nIn terms of statistics, I still have some confusion about the central limit theorem and normal distributions and if you can actually use parametric tests on non normal distributions, as there seems to be a lot of heated debate over this on the various statistics forums that I visited in hope of getting an answer to this question. I decided to play it safe and use a non parametric test, but I do want to learn more about how and when you can violate assumptions if you should at all.\n","date":"2024-01-12T00:00:00Z","image":"https://michelleyg1.github.io/p/total-cholesterol-cdc-nhanes-analysis/images/purple_hu3d03a01dcc18bc5be0e67db3d8d209a6_1915810_120x120_fill_q75_box_smart1.jpeg","permalink":"https://michelleyg1.github.io/p/total-cholesterol-cdc-nhanes-analysis/","title":"Total Cholesterol CDC NHANES Analysis"},{"content":"I found this dataset by filtering through the various settings that they have on the National Agriculture Statistics Service quick stats tool to see the condition of blueberries by year and week in the state of New Jersey.\nA lot of people think that New Jersey is only the city and the shore, but its not called the Garden State for nothing! For its small size, New Jersey punches above its weight class in producing and exporting various agricultural products.\nOne crop that New Jersey is known for is its blueberries.\nLoad Package 1 library(tidyverse) 1 2 3 4 5 6 7 8 9 10 ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.4 ✔ readr 2.1.4 ## ✔ forcats 1.0.0 ✔ stringr 1.5.1 ## ✔ ggplot2 3.4.4 ✔ tibble 3.2.1 ## ✔ lubridate 1.9.3 ✔ tidyr 1.3.0 ## ✔ purrr 1.0.2 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (\u0026lt;http://conflicted.r-lib.org/\u0026gt;) to force all conflicts to become errors 1 library(janitor) 1 2 3 4 5 6 ## ## Attaching package: \u0026#39;janitor\u0026#39; ## ## The following objects are masked from \u0026#39;package:stats\u0026#39;: ## ## chisq.test, fisher.test Import Dataset 1 blueberries \u0026lt;- read_csv(\u0026#34;/Users/michellegulotta/Desktop/my_first_project/blueberries/blueberry.csv\u0026#34;) 1 2 3 4 5 6 7 8 9 10 ## Rows: 225 Columns: 21 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \u0026#34;,\u0026#34; ## chr (9): Program, Period, Geo Level, State, watershed_code, Commodity, Data... ## dbl (3): Year, State ANSI, Value ## lgl (8): Ag District, Ag District Code, County, County ANSI, Zip Code, Regi... ## date (1): Week Ending ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. 1 2 3 4 5 6 7 8 blueberries \u0026lt;- blueberries %\u0026gt;% janitor::clean_names(., \u0026#34;snake\u0026#34;) %\u0026gt;% select(year, period, week_ending, data_item, value) %\u0026gt;% rename( condition = data_item, percent = value, week_number = period ) %\u0026gt;% print() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## # A tibble: 225 × 5 ## year week_number week_ending condition percent ## \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 2023 WEEK #26 2023-07-02 BLUEBERRIES, TAME - CONDITION, MEASURE… 0 ## 2 2023 WEEK #26 2023-07-02 BLUEBERRIES, TAME - CONDITION, MEASURE… 0 ## 3 2023 WEEK #26 2023-07-02 BLUEBERRIES, TAME - CONDITION, MEASURE… 100 ## 4 2023 WEEK #26 2023-07-02 BLUEBERRIES, TAME - CONDITION, MEASURE… 0 ## 5 2023 WEEK #26 2023-07-02 BLUEBERRIES, TAME - CONDITION, MEASURE… 0 ## 6 2023 WEEK #27 2023-07-09 BLUEBERRIES, TAME - CONDITION, MEASURE… 18 ## 7 2023 WEEK #27 2023-07-09 BLUEBERRIES, TAME - CONDITION, MEASURE… 19 ## 8 2023 WEEK #27 2023-07-09 BLUEBERRIES, TAME - CONDITION, MEASURE… 44 ## 9 2023 WEEK #27 2023-07-09 BLUEBERRIES, TAME - CONDITION, MEASURE… 19 ## 10 2023 WEEK #27 2023-07-09 BLUEBERRIES, TAME - CONDITION, MEASURE… 0 ## # ℹ 215 more rows Cleaning Data Clean up Condition and Week Number Column I wanted to clean up the condition column as I noticed it was pretty redundant, and all we really needed was the condition. This would also make it eaiser as this is going to be the legend on our graph. Another thing that I wanted to do was to make the week number column more simple, as the name of the variable already tells us that this is the week number, so all we really need in the observation is the number.\n1 2 blueberries$condition \u0026lt;- str_replace_all(blueberries$condition, \u0026#34;BLUEBERRIES, TAME - CONDITION, MEASURED IN PCT\u0026#34;, \u0026#34;\u0026#34;) blueberries$week_number \u0026lt;- str_replace_all(blueberries$week_number, \u0026#34;WEEK #\u0026#34;, \u0026#34;\u0026#34;) Checking to make sure that the different conditions look good\n1 unique(blueberries$condition) 1 ## [1] \u0026#34; EXCELLENT\u0026#34; \u0026#34; FAIR\u0026#34; \u0026#34; GOOD\u0026#34; \u0026#34; POOR\u0026#34; \u0026#34; VERY POOR\u0026#34; It looks like there\u0026rsquo;s some random leading and trailing white space, so I\u0026rsquo;m going to clean that up using the trimws() function, as well as the str_to_title() function to make it more readable and look nicer on our graph\n1 2 blueberries$condition \u0026lt;- trimws(blueberries$condition) blueberries$condition \u0026lt;- str_to_title(blueberries$condition) Checking the conditions again\n1 unique(blueberries$condition) 1 ## [1] \u0026#34;Excellent\u0026#34; \u0026#34;Fair\u0026#34; \u0026#34;Good\u0026#34; \u0026#34;Poor\u0026#34; \u0026#34;Very Poor\u0026#34; Looks good! Time to make a data visualization\nData Visualization 1 2 3 4 5 6 blueberries_2021 \u0026lt;- blueberries %\u0026gt;% filter(year == 2021) %\u0026gt;% mutate( condition_f = factor(condition) ) %\u0026gt;% print() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## # A tibble: 55 × 6 ## year week_number week_ending condition percent condition_f ## \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;date\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; ## 1 2021 25 2021-06-27 Excellent 25 Excellent ## 2 2021 25 2021-06-27 Fair 25 Fair ## 3 2021 25 2021-06-27 Good 50 Good ## 4 2021 25 2021-06-27 Poor 0 Poor ## 5 2021 25 2021-06-27 Very Poor 0 Very Poor ## 6 2021 26 2021-07-04 Excellent 84 Excellent ## 7 2021 26 2021-07-04 Fair 8 Fair ## 8 2021 26 2021-07-04 Good 8 Good ## 9 2021 26 2021-07-04 Poor 0 Poor ## 10 2021 26 2021-07-04 Very Poor 0 Very Poor ## # ℹ 45 more rows Factor to Change Order of Legend One of the problems that I came across while trying to make this graph was that the legend would appear in alphabetical order rather than in the order that made sense from excellent to very poor. After some trying and researching solutions, I realized that I could use the factor() function to change the order of the levels.\n1 2 blueberries_2021$condition_f \u0026lt;- factor(blueberries_2021$condition_f, levels = c(\u0026#34;Excellent\u0026#34;, \u0026#34;Good\u0026#34;, \u0026#34;Fair\u0026#34;, \u0026#34;Poor\u0026#34;, \u0026#34;Very Poor\u0026#34;)) Make Plot 1 2 3 4 5 6 7 8 9 10 11 ggplot(blueberries_2021, aes(x = week_ending, y = percent, fill = condition_f)) + geom_area(alpha = 0.5, position = \u0026#34;identity\u0026#34;) + scale_fill_manual(values = c(\u0026#34;#785EF0\u0026#34;, \u0026#34;#009E73\u0026#34;, \u0026#34;#FFB000\u0026#34;, \u0026#34;#FE6100\u0026#34;, \u0026#34;#DC267F\u0026#34;)) + labs(title = \u0026#34;Condition of Blueberries Measured in Percent in New Jersey in 2021\u0026#34;, x = \u0026#34;Week\u0026#34;, y = \u0026#34;Percent\u0026#34;, fill = \u0026#34;Condition\u0026#34;, caption = \u0026#34;Source: USDA National Agrigultural Statistics Service\u0026#34;) + theme_light() Conclusion Now it\u0026rsquo;s the beginning of January but this has me looking forward to the beginning of July!\nWorking on this specific visualization helped me work on my data cleaning skills. I also learned more about how factors work and how R automatically puts a character vector in alphabetical order, and that in order to get it to appear in the order you want on a legend, you have to change the order of the factor variable. I didn\u0026rsquo;t think about that before I started but it definitely makes sense, R doesn\u0026rsquo;t just know how humans rank the quality of blueberries.\nI also learned about geom_area(), I first tried to use geom_line() and was able to make that pretty easily, but when I tried to change it to geom_area() there was a lot that I had to change in order to get the effect that I wanted on my graph.\n","date":"2024-01-07T00:00:00Z","image":"https://michelleyg1.github.io/p/jersey-blueberries/images/blueberry_hu3d03a01dcc18bc5be0e67db3d8d209a6_1579336_120x120_fill_q75_box_smart1.jpeg","permalink":"https://michelleyg1.github.io/p/jersey-blueberries/","title":"Jersey Blueberries"},{"content":"I found this interesting dataset on Kaggle and wanted to do an exploratory analysis as I also have had asthma since I was a kid and wanted to see if I could find any interesting patterns within the data.\nLoad Packages 1 2 3 4 suppressPackageStartupMessages({ library(tidyverse) library(janitor) }) Import Dataset 1 2 3 asthma \u0026lt;- read.csv(\u0026#34;/Users/michellegulotta/Desktop/my_first_project/asthma/CDIAsthmaByStateTransposed2010-2020.csv\u0026#34;) asthma \u0026lt;- asthma %\u0026gt;% janitor::clean_names(., \u0026#34;snake\u0026#34;) Taking a look at the first few rows of the data to see what kind of information this dataset is providing\n1 head(asthma) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## geo_loc year state pop_est ## 1 POINT (-86.63186076199969 32.84057112200048) 2010 Alabama 4785514 ## 2 POINT (-147.72205903599973 64.84507995700051) 2010 Alaska 713982 ## 3 POINT (-111.76381127699972 34.865970280000454) 2010 Arizona 6407342 ## 4 POINT (-92.27449074299966 34.74865012400045) 2010 Arkansas 2921998 ## 5 POINT (-120.99999953799971 37.63864012300047) 2010 California 37319550 ## 6 POINT (-106.13361092099967 38.843840757000464) 2010 Colorado 5047539 ## f_fatal m_fatal o_fatal f_er m_er o_er f_hosp m_hosp o_hosp ## 1 44 17 61 NA NA NA NA NA NA ## 2 NA NA NA NA NA NA NA NA NA ## 3 31 27 58 22280 18335 40650 4717 3352 8073 ## 4 29 8 37 NA NA NA 1876 962 2841 ## 5 251 152 403 116571 96999 217637 19399 12958 34583 ## 6 33 15 48 NA NA NA 2385 1942 4336 Asthma Fatalities by Gender in New Jersey Data Visualization Clean Up Data Since its my home state, I decided to narrow the data that I wanted to look at down a bit to just New Jersey. I also only was interested in looking at fatalities for this particular graph as it is the most severe type of asthma incident recorded in this data.\nThe first thing that I needed to do was to pivot the data so that gender was its own observation, I originally missed out on this step when I was trying to make the graph and had a hard time coming up with the ggplot code as I was just repeating adding a different shape to my graph for each column. After a bit of trial and error I realized there was probably a way to do it where I wouldn’t have to add the columns individually as their own geoms.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 nj_asthma_fatalities \u0026lt;- asthma %\u0026gt;% filter(state == \u0026#34;New Jersey\u0026#34;) %\u0026gt;% select(year, ends_with(\u0026#34;_fatal\u0026#34;)) %\u0026gt;% pivot_longer( cols = ends_with(\u0026#34;_fatal\u0026#34;), names_to = \u0026#34;gender\u0026#34;, values_to = \u0026#34;fatalities\u0026#34;, names_pattern = \u0026#34;(.*)_fatal\u0026#34; ) %\u0026gt;% mutate( gender = factor(gender, c(\u0026#34;f\u0026#34;, \u0026#34;m\u0026#34;, \u0026#34;o\u0026#34;), c(\u0026#34;Female\u0026#34;, \u0026#34;Male\u0026#34;, \u0026#34;Overall\u0026#34;)) ) %\u0026gt;% print() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## # A tibble: 33 × 3 ## year gender fatalities ## \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; ## 1 2010 Female 49 ## 2 2010 Male 31 ## 3 2010 Overall 80 ## 4 2011 Female 62 ## 5 2011 Male 32 ## 6 2011 Overall 94 ## 7 2012 Female 63 ## 8 2012 Male 40 ## 9 2012 Overall 103 ## 10 2013 Female 73 ## # ℹ 23 more rows Create a Graph Now to take my newly pivoted data and create a graph using the ggplot2 package:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 ggplot(data = nj_asthma_fatalities) + geom_smooth(mapping = aes( x = year, y = fatalities, group = gender, color = gender), se = FALSE) + scale_color_manual(values = c(\u0026#34;pink\u0026#34;, \u0026#34;blue\u0026#34;, \u0026#34;black\u0026#34;)) + scale_x_continuous(n.breaks = 10) + labs(title = \u0026#34;Asthma Fatalities in New Jersey by Gender from 2010 to 2020\u0026#34;, x = \u0026#34;Years\u0026#34;, y = \u0026#34;Number of Fatalities\u0026#34;) + theme(plot.title = element_text(hjust=0.5)) + theme_bw() 1 ## `geom_smooth()` using method = \u0026#39;loess\u0026#39; and formula = \u0026#39;y ~ x\u0026#39; This graph shows an interesting trend that at least in the state of New Jersey over the 2010s decade asthma fatality incidents increased and then decreased, just to increase once again around 2017. Also, another trend that caught my eye was that that females made up the majority of overall fatalities that were recorded.\nAs these are not proportional to the population, they do not tell us the whole story. I’m interested in seeing if the mortality rates show the same pattern as anyone living in New Jersey can tell you that the population has increased over this past decade just from the traffic alone, does the population change account for the increase in asthma fatality incidents?\nCalculate Mortality Rate per 100,000 People Column I calculated the cause specific mortality rate per 100,000 people in the whole population of the state.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 nj_asthma_mortality_rate \u0026lt;- asthma %\u0026gt;% filter(state == \u0026#34;New Jersey\u0026#34;) %\u0026gt;% select(year, pop_est, ends_with(\u0026#34;_fatal\u0026#34;)) %\u0026gt;% pivot_longer( cols = ends_with(\u0026#34;_fatal\u0026#34;), names_to = \u0026#34;gender\u0026#34;, values_to = \u0026#34;fatalities\u0026#34;, names_pattern = \u0026#34;(.*)_fatal\u0026#34; ) %\u0026gt;% mutate( gender = factor(gender, c(\u0026#34;f\u0026#34;, \u0026#34;m\u0026#34;, \u0026#34;o\u0026#34;), c(\u0026#34;Female\u0026#34;, \u0026#34;Male\u0026#34;, \u0026#34;Overall\u0026#34;)), mortality_rate = round(((fatalities / pop_est) * 100000), 2) ) %\u0026gt;% print() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## # A tibble: 33 × 5 ## year pop_est gender fatalities mortality_rate ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 2010 8799451 Female 49 0.56 ## 2 2010 8799451 Male 31 0.35 ## 3 2010 8799451 Overall 80 0.91 ## 4 2011 8828552 Female 62 0.7 ## 5 2011 8828552 Male 32 0.36 ## 6 2011 8828552 Overall 94 1.06 ## 7 2012 8845671 Female 63 0.71 ## 8 2012 8845671 Male 40 0.45 ## 9 2012 8845671 Overall 103 1.16 ## 10 2013 8857821 Female 73 0.82 ## # ℹ 23 more rows Create a Graph of Asthma Mortality Rate per 100,000 People and Group By Gender Then I used ggplot2 to graph this new column to compare the mortality rate per 100,000 people over the decade of 2010 to 2020 to see if the same trend emerges:\n1 2 3 4 5 6 7 8 9 10 11 12 13 ggplot(data = nj_asthma_mortality_rate) + geom_smooth(mapping = aes(x = year, y = mortality_rate, group = gender, color = gender), se = FALSE) + scale_color_manual(values = c(\u0026#34;pink\u0026#34;, \u0026#34;blue\u0026#34;, \u0026#34;black\u0026#34;)) + scale_x_continuous(n.breaks = 10) + labs(title = \u0026#34;Asthma Mortality Rate in New Jersey by Gender from 2010 to 2020\u0026#34;, x = \u0026#34;Years\u0026#34;, y = \u0026#34;Number of Fatalities\u0026#34;) + theme(plot.title = element_text(hjust=0.5)) + theme_bw() 1 ## `geom_smooth()` using method = \u0026#39;loess\u0026#39; and formula = \u0026#39;y ~ x\u0026#39; Interesting, the graphs look pretty much the same to me so the population increase is not the reason for the increase in asthma fatality incidents as the mortality rate from asthma follows the same pattern as the fatality incidents over time, as well as the gender disparity.\nNationwide Analysis of Gender Differences In Asthma Mortality Rate Clean Up Data 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 asthma_mortality \u0026lt;- asthma %\u0026gt;% select(year, state, pop_est, f_fatal, m_fatal) %\u0026gt;% pivot_longer( cols = ends_with(\u0026#34;_fatal\u0026#34;), names_to = \u0026#34;gender\u0026#34;, values_to = \u0026#34;fatalities\u0026#34;, names_pattern = \u0026#34;(.*)_fatal\u0026#34; ) %\u0026gt;% mutate( gender = factor(gender, c(\u0026#34;f\u0026#34;, \u0026#34;m\u0026#34;, \u0026#34;o\u0026#34;), c(\u0026#34;Female\u0026#34;, \u0026#34;Male\u0026#34;, \u0026#34;Overall\u0026#34;)), mortality_rate = round(((fatalities / pop_est) * 100000), 2) ) %\u0026gt;% filter(gender != \u0026#34;Overall\u0026#34;) %\u0026gt;% print() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## # A tibble: 1,122 × 6 ## year state pop_est gender fatalities mortality_rate ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 2010 Alabama 4785514 Female 44 0.92 ## 2 2010 Alabama 4785514 Male 17 0.36 ## 3 2010 Alaska 713982 Female NA NA ## 4 2010 Alaska 713982 Male NA NA ## 5 2010 Arizona 6407342 Female 31 0.48 ## 6 2010 Arizona 6407342 Male 27 0.42 ## 7 2010 Arkansas 2921998 Female 29 0.99 ## 8 2010 Arkansas 2921998 Male 8 0.27 ## 9 2010 California 37319550 Female 251 0.67 ## 10 2010 California 37319550 Male 152 0.41 ## # ℹ 1,112 more rows I noticed there were a decent amount of missing values just by glancing at this lets see how many exactly\n1 sum(is.na(asthma_mortality$mortality_rate)) 1 ## [1] 264 Hm, 264/1122 that is not that bad, also it does look like they\u0026rsquo;re states with limited populations, so that might be the reason is that there just weren\u0026rsquo;t any fatal asthma incidents in that particular year.\nI\u0026rsquo;m going to remove the missing values for our next step in this analysis\n1 2 3 asthma_mortality_no_miss \u0026lt;- asthma_mortality %\u0026gt;% drop_na(mortality_rate) %\u0026gt;% print() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## # A tibble: 858 × 6 ## year state pop_est gender fatalities mortality_rate ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 2010 Alabama 4785514 Female 44 0.92 ## 2 2010 Alabama 4785514 Male 17 0.36 ## 3 2010 Arizona 6407342 Female 31 0.48 ## 4 2010 Arizona 6407342 Male 27 0.42 ## 5 2010 Arkansas 2921998 Female 29 0.99 ## 6 2010 Arkansas 2921998 Male 8 0.27 ## 7 2010 California 37319550 Female 251 0.67 ## 8 2010 California 37319550 Male 152 0.41 ## 9 2010 Colorado 5047539 Female 33 0.65 ## 10 2010 Colorado 5047539 Male 15 0.3 ## # ℹ 848 more rows Create a Histogram of Fatal Asthma Incidents for Each Gender I then decided to create a histogram to look at how these asthma fatalities are distributed.\nI\u0026rsquo;m going to use ggplot2 to make a histogram comparing the distribution of mortality rates between the two populations\n1 2 3 4 5 6 ggplot(data = asthma_mortality_no_miss, aes(x = mortality_rate, fill = gender)) + geom_histogram(color = \u0026#34;black\u0026#34;) + scale_fill_manual(values=c(\u0026#34;pink\u0026#34;, \u0026#34;blue\u0026#34;)) + labs(title = \u0026#34;Asthma Mortality Rate by Gender in the USA from 2010 to 2020\u0026#34;, x = \u0026#34;Mortality Rate\u0026#34;, y= \u0026#34;Number of Observations\u0026#34;) 1 ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. It looks like there are some outliers, let me take a look at the data sorted by mortality rate descending\n1 asthma_mortality_no_miss[order(asthma_mortality_no_miss$mortality_rate, decreasing = TRUE),] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## # A tibble: 858 × 6 ## year state pop_est gender fatalities mortality_rate ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 2020 New Mexico 211839 Female 26 12.3 ## 2 2020 Pennsylvania 1299444 Female 97 7.46 ## 3 2020 Illinois 1278658 Male 89 6.96 ## 4 2020 Illinois 1278658 Female 88 6.88 ## 5 2020 New Mexico 211839 Male 13 6.14 ## 6 2020 Pennsylvania 1299444 Male 69 5.31 ## 7 2014 Mississippi 2991892 Female 39 1.3 ## 8 2016 Mississippi 2990595 Female 38 1.27 ## 9 2014 Oregon 3965447 Female 50 1.26 ## 10 2014 Iowa 3110643 Female 38 1.22 ## # ℹ 848 more rows Wow, it looks like in 2020 there was a huge increase due to the pandemic most likely. I\u0026rsquo;m going to take a look at the data from 2010-2019 to get a closer look at the distribution.\n1 2 3 asthma_mortality_drop_2020 \u0026lt;- asthma_mortality_no_miss %\u0026gt;% filter(year != 2020) %\u0026gt;% print() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## # A tibble: 780 × 6 ## year state pop_est gender fatalities mortality_rate ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 2010 Alabama 4785514 Female 44 0.92 ## 2 2010 Alabama 4785514 Male 17 0.36 ## 3 2010 Arizona 6407342 Female 31 0.48 ## 4 2010 Arizona 6407342 Male 27 0.42 ## 5 2010 Arkansas 2921998 Female 29 0.99 ## 6 2010 Arkansas 2921998 Male 8 0.27 ## 7 2010 California 37319550 Female 251 0.67 ## 8 2010 California 37319550 Male 152 0.41 ## 9 2010 Colorado 5047539 Female 33 0.65 ## 10 2010 Colorado 5047539 Male 15 0.3 ## # ℹ 770 more rows And repeat the histogram process with the 2010 to 2019 data\n1 2 3 4 5 6 ggplot(data = asthma_mortality_drop_2020, aes(x = mortality_rate, fill = gender)) + geom_histogram(color = \u0026#34;black\u0026#34;) + scale_fill_manual(values=c(\u0026#34;pink\u0026#34;, \u0026#34;blue\u0026#34;)) + labs(title = \u0026#34;Asthma Mortality Rate by Gender in the USA from 2010 to 2019\u0026#34;, x = \u0026#34;Mortality Rate\u0026#34;, y= \u0026#34;Number of Observations\u0026#34;) 1 ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. I want to compare the means of these populations to see if there is a statistically significant difference in fatal asthma incidence between the two genders throughout the whole USA.\nStatistical Testing From the histogram, these don\u0026rsquo;t really seem to fit a normal distribution, but rather a skewed distribution, but let\u0026rsquo;s run the Shapiro-Wilk test to be sure instead of just eyeballing it and assuming.\n1 2 options(scipen = 999) shapiro.test(asthma_mortality_no_miss$mortality_rate) 1 2 3 4 5 ## ## Shapiro-Wilk normality test ## ## data: asthma_mortality_no_miss$mortality_rate ## W = 0.27179, p-value \u0026lt; 0.00000000000000022 Okay, since the p value is not greater than 0.05, I can\u0026rsquo;t use a t-test as that assumes normal distribution.\nI\u0026rsquo;m going to go for a non-parametric test since we\u0026rsquo;re not assuming any particular distribution here to test my hypothesis that when it comes to asthma fatalities females have a higher mortality rate than males. Since I have two unpaired samples and I want to test how their values compare, I\u0026rsquo;m going to use the Mann-Whitney test.\n1 wilcox.test(asthma_mortality_no_miss$mortality_rate) 1 2 3 4 5 6 ## ## Wilcoxon signed rank test with continuity correction ## ## data: asthma_mortality_no_miss$mortality_rate ## V = 368511, p-value \u0026lt; 0.00000000000000022 ## alternative hypothesis: true location is not equal to 0 With these results we can reject the null hypothesis, and say within this data there is a statistically significant difference between the two populations.\nConclusion Before this analysis I had no idea of the gender differences that arise in asthma incidents, upon looking into this further after completing this analysis I came across a paper that discusses the gender differences in asthma prevalence and severity on a biological level.\nAccording to the Asthma and Allergy Network, In people under 18, it is more common for boys to have asthma than girls, but this prevalence switches when analyzing adult populations. The fact that women have a higher risk of death from asthma when compared to men is also confirmed by this source.\n","date":"2024-01-03T00:00:00Z","image":"https://michelleyg1.github.io/p/asthma-incidents-analysis/images/featured_hud7e36f7e20e71be184458283bdae4646_55974_120x120_fill_q75_box_smart1.jpeg","permalink":"https://michelleyg1.github.io/p/asthma-incidents-analysis/","title":"Asthma Incidents Analysis"}]